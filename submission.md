
# Applied Data Analytics

## Wedge Project

<!-- Any general commentary you'd like to say about the project --> 
General commentary.  This was a difficult project that I learned and grew with.

### Task 1

Files for this task: 
<!--  List of file or files here  --> 

#### Raw Data Files

* WedgeZipOfZips_Big
* extracted_zips_big
* clean_csvs

#### Code Files

* Task 1.ipynb: Loads all data into GBQ data set.

`File1 Name`: 
Description of what this file does.

WedgeZipOfZips_Big - the source files that are compreessed and in seperate folders
extracted_zips_big - the files from the above that are un-compressed and in a .csv
clean_csvs - the files whith the cleaning completed on turned into a .txt



### Task 2

* Files for this task: 
<!--  List of file or files here  --> 
all 53  tables in leafy-sunrise-403222.wedge_data.transArchive
Loads all data into GBQ data set.

`File1 Name`: 
Description of what this file does.
all 53  tables in leafy-sunrise-403222.wedge_data.transArchive - these created from task 1 uploading of the "clean_csvs"
<!--  Repeat for each file  --> 
	

### Task 3

* Files for this task: 
<!--  List of file or files here  --> 
all 53  tables in leafy-sunrise-403222.wedge_data.transArchive
reporting.db
Loads all data into GBQ data set.

`File1 Name`: 
Description of what this file does.
all 53  tables in leafy-sunrise-403222.wedge_data.transArchive - these used to create the reporting.db
<!--  Repeat for each file  --> 


## Query Comparison Results

Fill in the following table with the results from the 
queries contained in `gbq_assessment_query.sql`. You only
need to fill in relative difference on the rows where it applies. 
When calculating relative difference, use the formula 
` (your_results - john_results)/john_results)`. 



|  Query  |  Your Results  |  John's Results | Difference | Rel. Diff | 
|---|---|---|---|---|
| Total Rows  |85,760,139|85,760,139|0|0%|
| January 2012 Rows  |1,070,907|1,070,907|0|0%|
| October 2012 Rows  |1,042,287|1,042,287|0|0%|
| Month with Fewest  |February|February|No|NA|
| Num Rows in Month with Fewest  |6,556,770|6,556,770|0|0%|
| Month with Most  |May|May|No|NA|
| Num Rows in Month with Most  |7,578,372|7,578,372|No|NA|
| Null_TS  |7,123,781|7,123,792|-11|0%|
| Null_DT  |0|0|0|0%|
| Null_Local  |234,839|234843|-4|0%|
| Null_CN  |0|0|0|0%|
| Num 5 on High Volume Cards  |14987|14987|No|NA|
|  Num Rows for Number 5 |460325|460630|-305|0%|
| Num Rows for 18736  |12153|12153|0|0%|
| Product with Most Rows  |banana organic|banana organic|No|NA|
| Num Rows for that Product  |908,639|908,639|0|0%|
| Product with Fourth-Most Rows  |avocado hass organic|avocado hass organic|No|0%|
| Num Rows for that Product  |456,771|456,771|0|0%|
| Num Single Record Products  |2741|2769|-28|0%|
| Year with Highest Portion of Owner Rows  |2010|2010|No|NA|
| Fraction of Rows from Owners in that Year  |.7422|.7422|0|0%|
| Year with Lowest Portion of Owner Rows  |2017|2017|No|NA|
| Fraction of Rows from Owners in that Year  |.7513|.7513|0|0%|

## Reflections

<!-- I'd love to get 100-200 words on your experience doing the Wedge Project --> 
This project was stressfull and had me wishing I had more Python, Github, text editor and GBQ experince on basics before hand.  I know I learned a lot from this.  It was stressfull but has me wishing I understood why I ran into so many issues that others did not.  I wish I understood why my data types caused so many issues here. 
