{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_gbq\n",
    "import sqlite3\n",
    "import zipfile\n",
    "import csv\n",
    "import io\n",
    "import glob\n",
    "\n",
    "# Do our imports for the code\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from zipfile import ZipFile\n",
    "from google.cloud.exceptions import NotFound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extracting Zip Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory path where your ZIP files are located locally\n",
    "# Use a raw string for the path\n",
    "#directory_path = \"/Users/biancabostrom/Documents/ADA/Wedge Project/WedgeZipOfZips_Big\"\n",
    "directory_path = r'C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big'\n",
    "output_folder = 'extracted_zips_big'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201001_201003.zip\n",
      "Extracted transArchive_201001_201003.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201004_201006.zip\n",
      "Extracted transArchive_201004_201006.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201007_201009.zip\n",
      "Extracted transArchive_201007_201009.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201010_201012.zip\n",
      "Extracted transArchive_201010_201012.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201101_201103.zip\n",
      "Extracted transArchive_201101_201103.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201104.zip\n",
      "Extracted transArchive_201104.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201105.zip\n",
      "Extracted transArchive_201105.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201106.zip\n",
      "Extracted transArchive_201106.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201107_201109.zip\n",
      "Extracted transArchive_201107_201109.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201110_201112.zip\n",
      "Extracted transArchive_201110_201112.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201201_201203.zip\n",
      "Extracted transArchive_201201_201203.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201201_201203_inactive.zip\n",
      "Extracted transArchive_201201_201203_inactive.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201204_201206.zip\n",
      "Extracted transArchive_201204_201206.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201204_201206_inactive.zip\n",
      "Extracted transArchive_201204_201206_inactive.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201207_201209.zip\n",
      "Extracted transArchive_201207_201209.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201207_201209_inactive.zip\n",
      "Extracted transArchive_201207_201209_inactive.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201210_201212.zip\n",
      "Extracted transArchive_201210_201212.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201210_201212_inactive.zip\n",
      "Extracted transArchive_201210_201212_inactive.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201301_201303.zip\n",
      "Extracted transArchive_201301_201303.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201301_201303_inactive.zip\n",
      "Extracted transArchive_201301_201303_inactive.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201304_201306.zip\n",
      "Extracted transArchive_201304_201306.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201304_201306_inactive.zip\n",
      "Extracted transArchive_201304_201306_inactive.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201307_201309.zip\n",
      "Extracted transArchive_201307_201309.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201307_201309_inactive.zip\n",
      "Extracted transArchive_201307_201309_inactive.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201310_201312.zip\n",
      "Extracted transArchive_201310_201312.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201310_201312_inactive.zip\n",
      "Extracted transArchive_201310_201312_inactive.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201401_201403.zip\n",
      "Extracted transArchive_201401_201403.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201401_201403_inactive.zip\n",
      "Extracted transArchive_201401_201403_inactive.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201404_201406.zip\n",
      "Extracted transArchive_201404_201406.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201404_201406_inactive.zip\n",
      "Extracted transArchive_201404_201406_inactive.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201407_201409.zip\n",
      "Extracted transArchive_201407_201409.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201407_201409_inactive.zip\n",
      "Extracted transArchive_201407_201409_inactive.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201410_201412.zip\n",
      "Extracted transArchive_201410_201412.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201410_201412_inactive.zip\n",
      "Extracted transArchive_201410_201412_inactive.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201501_201503.zip\n",
      "Extracted transArchive_201501_201503.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201504_201506.zip\n",
      "Extracted transArchive_201504_201506.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201507_201509.zip\n",
      "Extracted transArchive_201507_201509.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201510.zip\n",
      "Extracted transArchive_201510.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201511.zip\n",
      "Extracted transArchive_201511.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201512.zip\n",
      "Extracted transArchive_201512.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201601.zip\n",
      "Extracted transArchive_201601.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201602.zip\n",
      "Extracted transArchive_201602.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201603.zip\n",
      "Extracted transArchive_201603.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201604.zip\n",
      "Extracted transArchive_201604.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201605.zip\n",
      "Extracted transArchive_201605.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201606.zip\n",
      "Extracted transArchive_201606.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201607.zip\n",
      "Extracted transArchive_201607.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201608.zip\n",
      "Extracted transArchive_201608.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201609.zip\n",
      "Extracted transArchive_201609.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201610.zip\n",
      "Extracted transArchive_201610.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201611.zip\n",
      "Extracted transArchive_201611.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201612.zip\n",
      "Extracted transArchive_201612.zip to extracted_zips_big\n",
      "Attempting to extract: C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\data\\WedgeZipOfZips_Big\\transArchive_201701.zip\n",
      "Extracted transArchive_201701.zip to extracted_zips_big\n",
      "All files extracted.\n"
     ]
    }
   ],
   "source": [
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate over all the files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.zip'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "        # Create a folder for each ZIP file\n",
    "        folder_name = os.path.splitext(filename)[0]\n",
    "        extract_path = os.path.join(output_folder)\n",
    "\n",
    "        # Print the file path for debugging\n",
    "        print(f\"Attempting to extract: {file_path}\")\n",
    "\n",
    "        try:\n",
    "            # Open the ZIP file\n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                # Extract all the contents into the directory\n",
    "                zip_ref.extractall(extract_path)\n",
    "                print(f\"Extracted {filename} to {extract_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting {filename}: {e}\")\n",
    "\n",
    "print(\"All files extracted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleaning files: headers, delimeters, nulls and quotes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_headers = [\n",
    "    \"datetime\", \"register_no\", \"emp_no\", \"trans_no\", \"upc\", \"description\", \"trans_type\", \"trans_subtype\",\n",
    "    \"trans_status\", \"department\", \"quantity\", \"Scale\", \"cost\", \"unitPrice\", \"total\", \"regPrice\", \"altPrice\",\n",
    "    \"tax\", \"taxexempt\", \"foodstamp\", \"wicable\", \"discount\", \"memDiscount\", \"discountable\", \"discounttype\",\n",
    "    \"voided\", \"percentDiscount\", \"ItemQtty\", \"volDiscType\", \"volume\", \"VolSpecial\", \"mixMatch\", \"matched\",\n",
    "    \"memType\", \"staff\", \"numflag\", \"itemstatus\", \"tenderstatus\", \"charflag\", \"varflag\", \"batchHeaderID\", \n",
    "    \"local\", \"organic\", \"display\", \"receipt\", \"card_no\", \"store\", \"branch\", \"match_id\", \"trans_id\"\n",
    "]\n",
    "# loop though all files in the directory\n",
    "for root, dirs, files in os.walk(output_folder):\n",
    "    for file in files:\n",
    "        full_path = os.path.join(root, file)\n",
    "        if file.endswith('.csv'):\n",
    "            with open(full_path,'r') as f:\n",
    "                first_line = f.readline().strip()\n",
    "\n",
    "            with open(full_path,'r') as f:\n",
    "                content = f.read()\n",
    "            # check if the file likly has headers based on the first line\n",
    "            if not first_line.startswith('\"datetime\"') and not first_line.startswith('datetime'):\n",
    "                content = ','.join(correct_headers) + '\\n' + content\n",
    "\n",
    "            content = content.replace('\\\"','inch')\n",
    "\n",
    "            with open(full_path,'w') as f:\n",
    "                f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bianca's info\n",
    "#service_path = \"/Users/biancabostrom/Documents/ADA/Wedge\\ Project/wedge-404400-cb3a632effa5.json\"\n",
    "#service_file = 'wedge-404400-cb3a632effa5.json' \n",
    "#gbq_proj_id = \"wedge-404400\" \n",
    "#gbq_dataset_id = \"wedge_data\"\n",
    "#credentials = service_account.Credentials.from_service_account_file(\"/Users/biancabostrom/Documents/ADA/Wedge Project/wedge-404400-cb3a632effa5.json\")\n",
    "\n",
    "# Spencer's info\n",
    "service_path = r\"C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\leafy-sunrise-403222-f51fcd80b921.json\"\n",
    "service_file = 'leafy-sunrise-403222-f51fcd80b921.json' # change this to your authentication information  \n",
    "gbq_proj_id = \"leafy-sunrise-403222\" # change this to your project. \n",
    "gbq_dataset_id = \"wedge_data\"\n",
    "credentials = service_account.Credentials.from_service_account_file(r\"C:\\Users\\hills\\Documents\\Fall2023\\ADA\\wedge-project\\leafy-sunrise-403222-f51fcd80b921.json\")\n",
    "\n",
    "private_key = service_path + service_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = [\n",
    "    {\"name\": \"datetime\", \"type\": \"TIMESTAMP\"},     # 1\n",
    "    {\"name\": \"register_no\", \"type\": \"FLOAT\"},      # 2\n",
    "    {\"name\": \"emp_no\", \"type\": \"FLOAT\"},           # 3\n",
    "    {\"name\": \"trans_no\", \"type\": \"FLOAT\"},         # 4\n",
    "    {\"name\": \"upc\", \"type\": \"STRING\"},             # 5\n",
    "    {\"name\": \"description\", \"type\": \"STRING\"},     # 6\n",
    "    {\"name\": \"trans_type\", \"type\": \"STRING\"},      # 7\n",
    "    {\"name\": \"trans_subtype\", \"type\": \"STRING\"},   # 8\n",
    "    {\"name\": \"trans_status\", \"type\": \"STRING\"},    # 9\n",
    "    {\"name\": \"department\", \"type\": \"FLOAT\"},       # 10\n",
    "    {\"name\": \"quantity\", \"type\": \"FLOAT\"},         # 11\n",
    "    {\"name\": \"Scale\", \"type\": \"FLOAT\"},            # 12\n",
    "    {\"name\": \"cost\", \"type\": \"FLOAT\"},             # 13\n",
    "    {\"name\": \"unitPrice\", \"type\": \"FLOAT\"},        # 14\n",
    "    {\"name\": \"total\", \"type\": \"FLOAT\"},            # 15\n",
    "    {\"name\": \"regPrice\", \"type\": \"FLOAT\"},         # 16\n",
    "    {\"name\": \"altPrice\", \"type\": \"FLOAT\"},         # 17\n",
    "    {\"name\": \"tax\", \"type\": \"FLOAT\"},              # 18\n",
    "    {\"name\": \"taxexempt\", \"type\": \"FLOAT\"},        # 19\n",
    "    {\"name\": \"foodstamp\", \"type\": \"FLOAT\"},        # 20\n",
    "    {\"name\": \"wicable\", \"type\": \"FLOAT\"},          # 21\n",
    "    {\"name\": \"discount\", \"type\": \"FLOAT\"},         # 22\n",
    "    {\"name\": \"memDiscount\", \"type\": \"FLOAT\"},      # 23\n",
    "    {\"name\": \"discountable\", \"type\": \"FLOAT\"},     # 24\n",
    "    {\"name\": \"discounttype\", \"type\": \"FLOAT\"},     # 25\n",
    "    {\"name\": \"voided\", \"type\": \"FLOAT\"},           # 26\n",
    "    {\"name\": \"percentDiscount\", \"type\": \"FLOAT\"},  # 27\n",
    "    {\"name\": \"ItemQtty\", \"type\": \"FLOAT\"},         # 28\n",
    "    {\"name\": \"volDiscType\", \"type\": \"FLOAT\"},      # 29\n",
    "    {\"name\": \"volume\", \"type\": \"FLOAT\"},           # 30\n",
    "    {\"name\": \"VolSpecial\", \"type\": \"FLOAT\"},       # 31\n",
    "    {\"name\": \"mixMatch\", \"type\": \"FLOAT\"},         # 32\n",
    "    {\"name\": \"matched\", \"type\": \"FLOAT\"},          # 33\n",
    "    {\"name\": \"memType\", \"type\": \"BOOLEAN\"},        # 34\n",
    "    {\"name\": \"staff\", \"type\": \"BOOLEAN\"},          # 35\n",
    "    {\"name\": \"numflag\", \"type\": \"FLOAT\"},          # 36\n",
    "    {\"name\": \"itemstatus\", \"type\": \"FLOAT\"},       # 37\n",
    "    {\"name\": \"tenderstatus\", \"type\": \"FLOAT\"},     # 38\n",
    "    {\"name\": \"charflag\", \"type\": \"STRING\"},        # 39\n",
    "    {\"name\": \"varflag\", \"type\": \"FLOAT\"},          # 40\n",
    "    {\"name\": \"batchHeaderID\", \"type\": \"BOOLEAN\"},  # 41\n",
    "    {\"name\": \"local\", \"type\": \"FLOAT\"},            # 42\n",
    "    {\"name\": \"organic\", \"type\": \"FLOAT\"},          # 43\n",
    "    {\"name\": \"display\", \"type\": \"BOOLEAN\"},        # 44\n",
    "    {\"name\": \"receipt\", \"type\": \"FLOAT\"},          # 45\n",
    "    {\"name\": \"card_no\", \"type\": \"FLOAT\"},          # 46\n",
    "    {\"name\": \"store\", \"type\": \"FLOAT\"},            # 47\n",
    "    {\"name\": \"branch\", \"type\": \"FLOAT\"},           # 48\n",
    "    {\"name\": \"match_id\", \"type\": \"FLOAT\"},         # 49\n",
    "    {\"name\": \"trans_id\", \"type\": \"FLOAT\"}          # 50\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_table_if_exists(gbq_dataset_id, table_name, credentials, gbq_proj_id):\n",
    "    client = bigquery.Client(credentials=credentials, project=gbq_proj_id)\n",
    "    table_id = f\"{gbq_proj_id}.{gbq_dataset_id}.{table_name}\"\n",
    "\n",
    "    try:\n",
    "        client.delete_table(table_id)\n",
    "        print(f\"deleted table '{table_id}'\")\n",
    "    except NotFound:\n",
    "        print(f\"table '{table_id}' not found, skipping deletion.\")\n",
    "\n",
    "def detect_delimiter(filename):\n",
    "    with open(filename,'r') as file:\n",
    "        first_line = file.readline()\n",
    "        return \";\" if \";\" in first_line else \",\"\n",
    "    \n",
    "def clean_dataframe(df):\n",
    "    float_columns = [\n",
    "        'register_no', 'emp_no', 'trans_no', 'department', 'quantity', 'Scale', 'cost', 'unitPrice', 'total', 'regPrice'\n",
    "        , 'altPrice', 'tax', 'taxexempt', 'foodstamp', 'wicable', 'discount', 'memDiscount', 'discountable', 'discounttype'\n",
    "        , 'voided', 'percentDiscount', 'ItemQtty', 'volDiscType', 'volume', 'VolSpecial', 'mixMatch', 'matched', 'numflag'\n",
    "        , 'itemstatus', 'tenderstatus', 'varflag', 'local', 'organic', 'receipt', 'card_no', 'store', 'branch', 'match_id'\n",
    "        ,'trans_id'\n",
    "    ]\n",
    "\n",
    "    boolean_columns = [ 'memType', 'staff', 'batchHeaderID', 'display']\n",
    "\n",
    "    string_columns = ['upc', 'description', 'trans_type', 'trans_subtype', 'trans_status', 'charflag']\n",
    "\n",
    "    for col in string_columns:\n",
    "        if col in df.columns:\n",
    "            df[col]  = df[col].astype(str)\n",
    "            df[col] = df[col].str.replace('\"', '', regex=False)\n",
    "\n",
    "    for col in float_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    df[float_columns] = df[float_columns].fillna(0)\n",
    "\n",
    "    for col in boolean_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(bool)\n",
    "\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
    "\n",
    "    replace_strings = [\"\\\\n\", \"\\\\\\\\\", \"nan\", \"NULL\"]\n",
    "    df.replace(replace_strings, \"\", inplace=True)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].str.strip()\n",
    "\n",
    "    for col in ['ItemQtty', 'reciept']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).str.replace('\"', '', regex=False)\n",
    "\n",
    "    # Print the first 20 rows for inspection\n",
    "    print(\"First 20 rows after cleaning:\")\n",
    "    print(df.head(20))\n",
    "\n",
    "    df = df.applymap(lambda x: None if x == '' else x)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Upload to GBQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CSV file: transArchive_201001_201003.csv\n",
      "Detected delimiter: ,\n",
      "table 'leafy-sunrise-403222.wedge_data.transArchive_201001_201003' not found, skipping deletion.\n",
      "Table 'leafy-sunrise-403222.wedge_data.transArchive_201001_201003' not found, skipping deletion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hills\\AppData\\Local\\Temp\\ipykernel_64848\\1095268161.py:44: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 rows after cleaning:\n",
      "   datetime  register_no  emp_no  trans_no                    upc  \\\n",
      "0       NaT          0.0     0.0       0.0            inchupcinch   \n",
      "1       NaT          0.0     0.0       0.0  inch0005385200400inch   \n",
      "2       NaT          0.0     0.0       0.0  inch0020631400000inch   \n",
      "3       NaT          0.0     0.0       0.0  inch0002433551303inch   \n",
      "4       NaT          0.0     0.0       0.0  inch0004850000139inch   \n",
      "5       NaT          0.0     0.0       0.0  inch0004850000139inch   \n",
      "6       NaT          0.0     0.0       0.0  inch0082704802560inch   \n",
      "7       NaT          0.0     0.0       0.0  inch0009396681120inch   \n",
      "8       NaT          0.0     0.0       0.0  inch0000000000051inch   \n",
      "9       NaT          0.0     0.0       0.0           inch0001inch   \n",
      "10      NaT          0.0     0.0       0.0              inch0inch   \n",
      "11      NaT          0.0     0.0       0.0       inchDISCOUNTinch   \n",
      "12      NaT          0.0     0.0       0.0            inchTAXinch   \n",
      "13      NaT          0.0     0.0       0.0  inch0002336320121inch   \n",
      "14      NaT          0.0     0.0       0.0  inch0003291700022inch   \n",
      "15      NaT          0.0     0.0       0.0  inch0079001103005inch   \n",
      "16      NaT          0.0     0.0       0.0           inch0002inch   \n",
      "17      NaT          0.0     0.0       0.0              inch0inch   \n",
      "18      NaT          0.0     0.0       0.0            inchTAXinch   \n",
      "19      NaT          0.0     0.0       0.0       inchDISCOUNTinch   \n",
      "\n",
      "                               description          trans_type  \\\n",
      "0                      inchdescriptioninch  inchtrans_typeinch   \n",
      "1            inchMedium Salsa 16oz GMGinch           inchIinch   \n",
      "2    inchChickenBreastSkinlessBonelessinch           inchIinch   \n",
      "3        inchTaco Seasoning 1.4oz Bearinch           inchIinch   \n",
      "4   inchOrange Juice/Some Pulp 64oz Trinch           inchIinch   \n",
      "5   inchOrange Juice/Some Pulp 64oz Trinch           inchIinch   \n",
      "6      inchShredded Mexican Cheese 8ozinch           inchIinch   \n",
      "7            inchEggs O.Large dozen OVinch           inchIinch   \n",
      "8                   inchBANANA Organicinch           inchIinch   \n",
      "9                      inchCredit Cardinch           inchTinch   \n",
      "10                          inchChangeinch           inchTinch   \n",
      "11                        inchDiscountinch           inchIinch   \n",
      "12                             inchTaxinch           inchAinch   \n",
      "13     inchNeutralizing Cordial 1oz EIinch           inchIinch   \n",
      "14       inchEaters Digest Tea 16ct TMinch           inchIinch   \n",
      "15          inchFem-Dophilus 30ct Jarrinch           inchIinch   \n",
      "16                     inchCredit Cardinch           inchTinch   \n",
      "17                          inchChangeinch           inchTinch   \n",
      "18                             inchTaxinch           inchAinch   \n",
      "19                        inchDiscountinch           inchIinch   \n",
      "\n",
      "            trans_subtype          trans_status  department  ...  \\\n",
      "0   inchtrans_subtypeinch  inchtrans_statusinch         0.0  ...   \n",
      "1               inch inch             inch inch         0.0  ...   \n",
      "2               inch inch             inch inch         0.0  ...   \n",
      "3               inch inch             inch inch         0.0  ...   \n",
      "4               inch inch             inch inch         0.0  ...   \n",
      "5               inch inch             inch inch         0.0  ...   \n",
      "6               inch inch             inch inch         0.0  ...   \n",
      "7               inch inch             inch inch         0.0  ...   \n",
      "8               inch inch             inch inch         0.0  ...   \n",
      "9              inchCCinch             inch0inch         0.0  ...   \n",
      "10             inchCAinch             inch0inch         0.0  ...   \n",
      "11              inch0inch             inch0inch         0.0  ...   \n",
      "12              inch0inch             inch0inch         0.0  ...   \n",
      "13              inch inch             inch inch         0.0  ...   \n",
      "14              inch inch             inch inch         0.0  ...   \n",
      "15              inch inch             inch inch         0.0  ...   \n",
      "16             inchCCinch             inch0inch         0.0  ...   \n",
      "17             inchCAinch             inch0inch         0.0  ...   \n",
      "18              inch0inch             inch0inch         0.0  ...   \n",
      "19              inch0inch             inch0inch         0.0  ...   \n",
      "\n",
      "    batchHeaderID  local  organic  display  receipt  card_no  store  branch  \\\n",
      "0            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "1            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "2            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "3            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "4            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "5            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "6            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "7            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "8            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "9            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "10           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "11           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "12           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "13           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "14           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "15           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "16           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "17           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "18           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "19           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "\n",
      "    match_id  trans_id  \n",
      "0        0.0       0.0  \n",
      "1        0.0       0.0  \n",
      "2        0.0       0.0  \n",
      "3        0.0       0.0  \n",
      "4        0.0       0.0  \n",
      "5        0.0       0.0  \n",
      "6        0.0       0.0  \n",
      "7        0.0       0.0  \n",
      "8        0.0       0.0  \n",
      "9        0.0       0.0  \n",
      "10       0.0       0.0  \n",
      "11       0.0       0.0  \n",
      "12       0.0       0.0  \n",
      "13       0.0       0.0  \n",
      "14       0.0       0.0  \n",
      "15       0.0       0.0  \n",
      "16       0.0       0.0  \n",
      "17       0.0       0.0  \n",
      "18       0.0       0.0  \n",
      "19       0.0       0.0  \n",
      "\n",
      "[20 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hills\\AppData\\Local\\Temp\\ipykernel_64848\\1095268161.py:61: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: None if x == '' else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading transArchive_201001_201003 to BigQuery...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CSV file: transArchive_201004_201006.csv\n",
      "Detected delimiter: ,\n",
      "table 'leafy-sunrise-403222.wedge_data.transArchive_201004_201006' not found, skipping deletion.\n",
      "Table 'leafy-sunrise-403222.wedge_data.transArchive_201004_201006' not found, skipping deletion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hills\\AppData\\Local\\Temp\\ipykernel_64848\\1095268161.py:44: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 rows after cleaning:\n",
      "   datetime  register_no  emp_no  trans_no                    upc  \\\n",
      "0       NaT          0.0     0.0       0.0            inchupcinch   \n",
      "1       NaT          0.0     0.0       0.0  inch0000827488333inch   \n",
      "2       NaT          0.0     0.0       0.0           inch0001inch   \n",
      "3       NaT          0.0     0.0       0.0  inch0065762221294inch   \n",
      "4       NaT          0.0     0.0       0.0              inch0inch   \n",
      "5       NaT          0.0     0.0       0.0       inchDISCOUNTinch   \n",
      "6       NaT          0.0     0.0       0.0            inchTAXinch   \n",
      "7       NaT          0.0     0.0       0.0  inch0000000000186inch   \n",
      "8       NaT          0.0     0.0       0.0  inch0000000000049inch   \n",
      "9       NaT          0.0     0.0       0.0            inchTAXinch   \n",
      "10      NaT          0.0     0.0       0.0              inch0inch   \n",
      "11      NaT          0.0     0.0       0.0       inchDISCOUNTinch   \n",
      "12      NaT          0.0     0.0       0.0              inch0inch   \n",
      "13      NaT          0.0     0.0       0.0  inch0000000040116inch   \n",
      "14      NaT          0.0     0.0       0.0           inch0002inch   \n",
      "15      NaT          0.0     0.0       0.0              inch0inch   \n",
      "16      NaT          0.0     0.0       0.0       inchDISCOUNTinch   \n",
      "17      NaT          0.0     0.0       0.0            inchTAXinch   \n",
      "18      NaT          0.0     0.0       0.0  inch0007234001152inch   \n",
      "19      NaT          0.0     0.0       0.0  inch0060265217005inch   \n",
      "\n",
      "                               description          trans_type  \\\n",
      "0                      inchdescriptioninch  inchtrans_typeinch   \n",
      "1    inchCrystallized Ginger 16oz Reedinch           inchIinch   \n",
      "2                      inchCredit Cardinch           inchTinch   \n",
      "3     inchO.Moroccan Mint Tea 16oz HoTinch           inchIinch   \n",
      "4                           inchChangeinch           inchTinch   \n",
      "5                         inchDiscountinch           inchIinch   \n",
      "6                              inchTaxinch           inchAinch   \n",
      "7   inchORANGES CaraCara Navel Organicinch           inchIinch   \n",
      "8                     inchWEDGE MUFFINinch           inchIinch   \n",
      "9                              inchTaxinch           inchAinch   \n",
      "10                          inchChangeinch           inchTinch   \n",
      "11                        inchDiscountinch           inchIinch   \n",
      "12                            inchCashinch           inchTinch   \n",
      "13      inchO.Salad with a Straw Smallinch           inchIinch   \n",
      "14                          inchEBT FSinch           inchTinch   \n",
      "15                          inchChangeinch           inchTinch   \n",
      "16                        inchDiscountinch           inchIinch   \n",
      "17                             inchTaxinch           inchAinch   \n",
      "18           inchOrange Juice 16oz Schinch           inchIinch   \n",
      "19   inchAlmond Apricot Bar 1.4oz Kindinch           inchIinch   \n",
      "\n",
      "            trans_subtype          trans_status  department  ...  \\\n",
      "0   inchtrans_subtypeinch  inchtrans_statusinch         0.0  ...   \n",
      "1               inch inch             inch inch         0.0  ...   \n",
      "2              inchCCinch                               0.0  ...   \n",
      "3               inch inch             inch inch         0.0  ...   \n",
      "4              inchCAinch                               0.0  ...   \n",
      "5                                                       0.0  ...   \n",
      "6                                                       0.0  ...   \n",
      "7               inch inch             inch inch         0.0  ...   \n",
      "8               inch inch             inch inch         0.0  ...   \n",
      "9                                                       0.0  ...   \n",
      "10             inchCAinch                               0.0  ...   \n",
      "11                                                      0.0  ...   \n",
      "12             inchCAinch                               0.0  ...   \n",
      "13              inch inch             inch inch         0.0  ...   \n",
      "14             inchEFinch                               0.0  ...   \n",
      "15             inchCAinch                               0.0  ...   \n",
      "16                                                      0.0  ...   \n",
      "17                                                      0.0  ...   \n",
      "18              inch inch             inch inch         0.0  ...   \n",
      "19              inch inch             inch inch         0.0  ...   \n",
      "\n",
      "    batchHeaderID  local  organic  display  receipt  card_no  store  branch  \\\n",
      "0            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "1            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "2            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "3            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "4            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "5            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "6            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "7            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "8            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "9            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "10           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "11           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "12           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "13           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "14           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "15           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "16           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "17           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "18           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "19           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "\n",
      "    match_id  trans_id  \n",
      "0        0.0       0.0  \n",
      "1        0.0       0.0  \n",
      "2        0.0       0.0  \n",
      "3        0.0       0.0  \n",
      "4        0.0       0.0  \n",
      "5        0.0       0.0  \n",
      "6        0.0       0.0  \n",
      "7        0.0       0.0  \n",
      "8        0.0       0.0  \n",
      "9        0.0       0.0  \n",
      "10       0.0       0.0  \n",
      "11       0.0       0.0  \n",
      "12       0.0       0.0  \n",
      "13       0.0       0.0  \n",
      "14       0.0       0.0  \n",
      "15       0.0       0.0  \n",
      "16       0.0       0.0  \n",
      "17       0.0       0.0  \n",
      "18       0.0       0.0  \n",
      "19       0.0       0.0  \n",
      "\n",
      "[20 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hills\\AppData\\Local\\Temp\\ipykernel_64848\\1095268161.py:61: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: None if x == '' else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading transArchive_201004_201006 to BigQuery...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CSV file: transArchive_201007_201009.csv\n",
      "Detected delimiter: ,\n",
      "table 'leafy-sunrise-403222.wedge_data.transArchive_201007_201009' not found, skipping deletion.\n",
      "Table 'leafy-sunrise-403222.wedge_data.transArchive_201007_201009' not found, skipping deletion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hills\\AppData\\Local\\Temp\\ipykernel_64848\\1095268161.py:44: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 rows after cleaning:\n",
      "   datetime  register_no  emp_no  trans_no                    upc  \\\n",
      "0       NaT          0.0     0.0       0.0            inchupcinch   \n",
      "1       NaT          0.0     0.0       0.0  inch0000000000049inch   \n",
      "2       NaT          0.0     0.0       0.0  inch0000000000049inch   \n",
      "3       NaT          0.0     0.0       0.0  inch0000000000049inch   \n",
      "4       NaT          0.0     0.0       0.0  inch0000000040421inch   \n",
      "5       NaT          0.0     0.0       0.0              inch0inch   \n",
      "6       NaT          0.0     0.0       0.0              inch0inch   \n",
      "7       NaT          0.0     0.0       0.0            inchTAXinch   \n",
      "8       NaT          0.0     0.0       0.0       inchDISCOUNTinch   \n",
      "9       NaT          0.0     0.0       0.0              inch0inch   \n",
      "10      NaT          0.0     0.0       0.0              inch0inch   \n",
      "11      NaT          0.0     0.0       0.0            inchTAXinch   \n",
      "12      NaT          0.0     0.0       0.0       inchDISCOUNTinch   \n",
      "13      NaT          0.0     0.0       0.0  inch0000000040400inch   \n",
      "14      NaT          0.0     0.0       0.0  inch0000000000099inch   \n",
      "15      NaT          0.0     0.0       0.0  inch0000000000099inch   \n",
      "16      NaT          0.0     0.0       0.0  inch0000000000099inch   \n",
      "17      NaT          0.0     0.0       0.0              inch0inch   \n",
      "18      NaT          0.0     0.0       0.0            inchTAXinch   \n",
      "19      NaT          0.0     0.0       0.0  inch0000000000099inch   \n",
      "\n",
      "                        description          trans_type  \\\n",
      "0               inchdescriptioninch  inchtrans_typeinch   \n",
      "1              inchWEDGE MUFFINinch           inchIinch   \n",
      "2              inchWEDGE MUFFINinch           inchIinch   \n",
      "3              inchWEDGE MUFFINinch           inchIinch   \n",
      "4   inchCoffee Hot Organic 16ozinch           inchIinch   \n",
      "5                      inchCashinch           inchTinch   \n",
      "6                    inchChangeinch           inchTinch   \n",
      "7                       inchTaxinch           inchAinch   \n",
      "8                  inchDiscountinch           inchIinch   \n",
      "9                      inchCashinch           inchTinch   \n",
      "10                   inchChangeinch           inchTinch   \n",
      "11                      inchTaxinch           inchAinch   \n",
      "12                 inchDiscountinch           inchIinch   \n",
      "13  inchCoffee Hot Organic 12ozinch           inchIinch   \n",
      "14             inchWEDGE COOKIEinch           inchIinch   \n",
      "15             inchWEDGE COOKIEinch           inchIinch   \n",
      "16             inchWEDGE COOKIEinch           inchIinch   \n",
      "17                   inchChangeinch           inchTinch   \n",
      "18                      inchTaxinch           inchAinch   \n",
      "19             inchWEDGE COOKIEinch           inchIinch   \n",
      "\n",
      "            trans_subtype          trans_status  department  ...  \\\n",
      "0   inchtrans_subtypeinch  inchtrans_statusinch         0.0  ...   \n",
      "1               inch inch             inch inch         0.0  ...   \n",
      "2               inch inch             inch inch         0.0  ...   \n",
      "3               inch inch             inch inch         0.0  ...   \n",
      "4               inch inch             inch inch         0.0  ...   \n",
      "5              inchCAinch                               0.0  ...   \n",
      "6              inchCAinch                               0.0  ...   \n",
      "7                                                       0.0  ...   \n",
      "8                                                       0.0  ...   \n",
      "9              inchCAinch                               0.0  ...   \n",
      "10             inchCAinch                               0.0  ...   \n",
      "11                                                      0.0  ...   \n",
      "12                                                      0.0  ...   \n",
      "13              inch inch             inch inch         0.0  ...   \n",
      "14              inch inch             inch inch         0.0  ...   \n",
      "15              inch inch             inch inch         0.0  ...   \n",
      "16              inch inch             inch inch         0.0  ...   \n",
      "17             inchCAinch                               0.0  ...   \n",
      "18                                                      0.0  ...   \n",
      "19              inch inch             inch inch         0.0  ...   \n",
      "\n",
      "    batchHeaderID  local  organic  display  receipt  card_no  store  branch  \\\n",
      "0            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "1            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "2            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "3            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "4            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "5            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "6            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "7            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "8            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "9            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "10           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "11           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "12           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "13           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "14           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "15           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "16           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "17           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "18           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "19           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "\n",
      "    match_id  trans_id  \n",
      "0        0.0       0.0  \n",
      "1        0.0       0.0  \n",
      "2        0.0       0.0  \n",
      "3        0.0       0.0  \n",
      "4        0.0       0.0  \n",
      "5        0.0       0.0  \n",
      "6        0.0       0.0  \n",
      "7        0.0       0.0  \n",
      "8        0.0       0.0  \n",
      "9        0.0       0.0  \n",
      "10       0.0       0.0  \n",
      "11       0.0       0.0  \n",
      "12       0.0       0.0  \n",
      "13       0.0       0.0  \n",
      "14       0.0       0.0  \n",
      "15       0.0       0.0  \n",
      "16       0.0       0.0  \n",
      "17       0.0       0.0  \n",
      "18       0.0       0.0  \n",
      "19       0.0       0.0  \n",
      "\n",
      "[20 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hills\\AppData\\Local\\Temp\\ipykernel_64848\\1095268161.py:61: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: None if x == '' else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading transArchive_201007_201009 to BigQuery...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CSV file: transArchive_201010_201012.csv\n",
      "Detected delimiter: ,\n",
      "table 'leafy-sunrise-403222.wedge_data.transArchive_201010_201012' not found, skipping deletion.\n",
      "Table 'leafy-sunrise-403222.wedge_data.transArchive_201010_201012' not found, skipping deletion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hills\\AppData\\Local\\Temp\\ipykernel_64848\\1095268161.py:44: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 rows after cleaning:\n",
      "   datetime  register_no  emp_no  trans_no                    upc  \\\n",
      "0       NaT          0.0     0.0       0.0            inchupcinch   \n",
      "1       NaT          0.0     0.0       0.0  inch0000000008011inch   \n",
      "2       NaT          0.0     0.0       0.0  inch0000000008011inch   \n",
      "3       NaT          0.0     0.0       0.0  inch0000000008011inch   \n",
      "4       NaT          0.0     0.0       0.0              inch0inch   \n",
      "5       NaT          0.0     0.0       0.0              inch0inch   \n",
      "6       NaT          0.0     0.0       0.0       inchDISCOUNTinch   \n",
      "7       NaT          0.0     0.0       0.0            inchTAXinch   \n",
      "8       NaT          0.0     0.0       0.0  inch0000000000399inch   \n",
      "9       NaT          0.0     0.0       0.0  inch0000000040208inch   \n",
      "10      NaT          0.0     0.0       0.0              inch0inch   \n",
      "11      NaT          0.0     0.0       0.0              inch0inch   \n",
      "12      NaT          0.0     0.0       0.0       inchDISCOUNTinch   \n",
      "13      NaT          0.0     0.0       0.0            inchTAXinch   \n",
      "14      NaT          0.0     0.0       0.0  inch0000000000057inch   \n",
      "15      NaT          0.0     0.0       0.0  inch0003068409333inch   \n",
      "16      NaT          0.0     0.0       0.0              inch0inch   \n",
      "17      NaT          0.0     0.0       0.0  inch0002836783479inch   \n",
      "18      NaT          0.0     0.0       0.0  inch0002836783479inch   \n",
      "19      NaT          0.0     0.0       0.0              inch0inch   \n",
      "\n",
      "                               description          trans_type  \\\n",
      "0                      inchdescriptioninch  inchtrans_typeinch   \n",
      "1                      inchWEDGE CLASSinch           inchIinch   \n",
      "2                      inchWEDGE CLASSinch           inchIinch   \n",
      "3                      inchWEDGE CLASSinch           inchIinch   \n",
      "4                      inchCredit Cardinch           inchTinch   \n",
      "5                           inchChangeinch           inchTinch   \n",
      "6                         inchDiscountinch           inchIinch   \n",
      "7                              inchTaxinch           inchAinch   \n",
      "8                  inchArugula Organicinch           inchIinch   \n",
      "9            inchCity Sunrise Smoothieinch           inchIinch   \n",
      "10                     inchCredit Cardinch           inchTinch   \n",
      "11                          inchChangeinch           inchTinch   \n",
      "12                        inchDiscountinch           inchIinch   \n",
      "13                             inchTaxinch           inchAinch   \n",
      "14                  inchMini Focaccia inch           inchIinch   \n",
      "15       inchO.Ginger Snaps 8oz Mi-Delinch           inchIinch   \n",
      "16                     inchCredit Cardinch           inchTinch   \n",
      "17  inchGrpfrt Berg.Soap Refill 17.5ozinch           inchIinch   \n",
      "18  inchGrpfrt Berg.Soap Refill 17.5ozinch           inchIinch   \n",
      "19                          inchChangeinch           inchTinch   \n",
      "\n",
      "            trans_subtype          trans_status  department  ...  \\\n",
      "0   inchtrans_subtypeinch  inchtrans_statusinch         0.0  ...   \n",
      "1               inch inch             inch inch         0.0  ...   \n",
      "2               inch inch             inch inch         0.0  ...   \n",
      "3               inch inch             inch inch         0.0  ...   \n",
      "4              inchCCinch             inch inch         0.0  ...   \n",
      "5              inchCAinch             inch inch         0.0  ...   \n",
      "6               inch inch             inch inch         0.0  ...   \n",
      "7               inch inch             inch inch         0.0  ...   \n",
      "8               inch inch             inch inch         0.0  ...   \n",
      "9               inch inch             inch inch         0.0  ...   \n",
      "10             inchCCinch             inch inch         0.0  ...   \n",
      "11             inchCAinch             inch inch         0.0  ...   \n",
      "12              inch inch             inch inch         0.0  ...   \n",
      "13              inch inch             inch inch         0.0  ...   \n",
      "14              inch inch             inch inch         0.0  ...   \n",
      "15              inch inch             inch inch         0.0  ...   \n",
      "16             inchCCinch             inch inch         0.0  ...   \n",
      "17              inch inch             inch inch         0.0  ...   \n",
      "18              inch inch             inch inch         0.0  ...   \n",
      "19             inchCAinch             inch inch         0.0  ...   \n",
      "\n",
      "    batchHeaderID  local  organic  display  receipt  card_no  store  branch  \\\n",
      "0            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "1            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "2            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "3            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "4            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "5            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "6            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "7            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "8            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "9            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "10           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "11           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "12           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "13           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "14           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "15           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "16           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "17           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "18           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "19           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "\n",
      "    match_id  trans_id  \n",
      "0        0.0       0.0  \n",
      "1        0.0       0.0  \n",
      "2        0.0       0.0  \n",
      "3        0.0       0.0  \n",
      "4        0.0       0.0  \n",
      "5        0.0       0.0  \n",
      "6        0.0       0.0  \n",
      "7        0.0       0.0  \n",
      "8        0.0       0.0  \n",
      "9        0.0       0.0  \n",
      "10       0.0       0.0  \n",
      "11       0.0       0.0  \n",
      "12       0.0       0.0  \n",
      "13       0.0       0.0  \n",
      "14       0.0       0.0  \n",
      "15       0.0       0.0  \n",
      "16       0.0       0.0  \n",
      "17       0.0       0.0  \n",
      "18       0.0       0.0  \n",
      "19       0.0       0.0  \n",
      "\n",
      "[20 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hills\\AppData\\Local\\Temp\\ipykernel_64848\\1095268161.py:61: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: None if x == '' else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading transArchive_201010_201012 to BigQuery...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CSV file: transArchive_201101_201103.csv\n",
      "Detected delimiter: ,\n",
      "table 'leafy-sunrise-403222.wedge_data.transArchive_201101_201103' not found, skipping deletion.\n",
      "Table 'leafy-sunrise-403222.wedge_data.transArchive_201101_201103' not found, skipping deletion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hills\\AppData\\Local\\Temp\\ipykernel_64848\\1095268161.py:44: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 rows after cleaning:\n",
      "   datetime  register_no  emp_no  trans_no                    upc  \\\n",
      "0       NaT          0.0     0.0       0.0            inchupcinch   \n",
      "1       NaT          0.0     0.0       0.0  inch0000000040400inch   \n",
      "2       NaT          0.0     0.0       0.0              inch0inch   \n",
      "3       NaT          0.0     0.0       0.0              inch0inch   \n",
      "4       NaT          0.0     0.0       0.0       inchDISCOUNTinch   \n",
      "5       NaT          0.0     0.0       0.0            inchTAXinch   \n",
      "6       NaT          0.0     0.0       0.0  inch0000000000050inch   \n",
      "7       NaT          0.0     0.0       0.0  inch0000000000050inch   \n",
      "8       NaT          0.0     0.0       0.0  inch0000000008026inch   \n",
      "9       NaT          0.0     0.0       0.0              inch0inch   \n",
      "10      NaT          0.0     0.0       0.0              inch0inch   \n",
      "11      NaT          0.0     0.0       0.0       inchDISCOUNTinch   \n",
      "12      NaT          0.0     0.0       0.0            inchTAXinch   \n",
      "13      NaT          0.0     0.0       0.0  inch0007514000500inch   \n",
      "14      NaT          0.0     0.0       0.0  inch0007514000500inch   \n",
      "15      NaT          0.0     0.0       0.0  inch0007514000500inch   \n",
      "16      NaT          0.0     0.0       0.0  inch0020694800000inch   \n",
      "17      NaT          0.0     0.0       0.0  inch0020158200000inch   \n",
      "18      NaT          0.0     0.0       0.0  inch0001294404497inch   \n",
      "19      NaT          0.0     0.0       0.0  inch0000000001014inch   \n",
      "\n",
      "                              description          trans_type  \\\n",
      "0                     inchdescriptioninch  inchtrans_typeinch   \n",
      "1         inchCoffee Hot Organic 12ozinch           inchIinch   \n",
      "2                            inchCashinch           inchTinch   \n",
      "3                          inchChangeinch           inchTinch   \n",
      "4                        inchDiscountinch           inchIinch   \n",
      "5                             inchTaxinch           inchAinch   \n",
      "6                    inchMonkey Breadinch           inchIinch   \n",
      "7                    inchMonkey Breadinch           inchIinch   \n",
      "8                  inchGift Card Soldinch           inchIinch   \n",
      "9                     inchCredit Cardinch           inchTinch   \n",
      "10                         inchChangeinch           inchTinch   \n",
      "11                       inchDiscountinch           inchIinch   \n",
      "12                            inchTaxinch           inchAinch   \n",
      "13          inchSpring Water 1.5L CGeinch           inchIinch   \n",
      "14          inchSpring Water 1.5L CGeinch           inchIinch   \n",
      "15          inchSpring Water 1.5L CGeinch           inchIinch   \n",
      "16                inchPickled Herringinch           inchIinch   \n",
      "17  inchGreek Salad/Balsamic Vinaigr.inch           inchIinch   \n",
      "18     inchO.Fresh Orange Juice Quartinch           inchIinch   \n",
      "19         inchGREEN PATCH REDEMPTIONinch           inchIinch   \n",
      "\n",
      "            trans_subtype          trans_status  department  ...  \\\n",
      "0   inchtrans_subtypeinch  inchtrans_statusinch         0.0  ...   \n",
      "1               inch inch             inch inch         0.0  ...   \n",
      "2              inchCAinch             inch inch         0.0  ...   \n",
      "3              inchCAinch             inch inch         0.0  ...   \n",
      "4               inch inch             inch inch         0.0  ...   \n",
      "5               inch inch             inch inch         0.0  ...   \n",
      "6               inch inch             inch inch         0.0  ...   \n",
      "7               inch inch             inchVinch         0.0  ...   \n",
      "8               inch inch             inch inch         0.0  ...   \n",
      "9              inchCCinch             inch inch         0.0  ...   \n",
      "10             inchCAinch             inch inch         0.0  ...   \n",
      "11              inch inch             inch inch         0.0  ...   \n",
      "12              inch inch             inch inch         0.0  ...   \n",
      "13              inch inch             inch inch         0.0  ...   \n",
      "14              inch inch             inch inch         0.0  ...   \n",
      "15              inch inch             inch inch         0.0  ...   \n",
      "16              inch inch             inch inch         0.0  ...   \n",
      "17              inch inch             inch inch         0.0  ...   \n",
      "18              inch inch             inch inch         0.0  ...   \n",
      "19              inch inch             inch inch         0.0  ...   \n",
      "\n",
      "    batchHeaderID  local  organic  display  receipt  card_no  store  branch  \\\n",
      "0            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "1            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "2            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "3            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "4            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "5            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "6            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "7            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "8            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "9            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "10           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "11           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "12           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "13           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "14           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "15           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "16           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "17           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "18           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "19           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "\n",
      "    match_id  trans_id  \n",
      "0        0.0       0.0  \n",
      "1        0.0       0.0  \n",
      "2        0.0       0.0  \n",
      "3        0.0       0.0  \n",
      "4        0.0       0.0  \n",
      "5        0.0       0.0  \n",
      "6        0.0       0.0  \n",
      "7        0.0       0.0  \n",
      "8        0.0       0.0  \n",
      "9        0.0       0.0  \n",
      "10       0.0       0.0  \n",
      "11       0.0       0.0  \n",
      "12       0.0       0.0  \n",
      "13       0.0       0.0  \n",
      "14       0.0       0.0  \n",
      "15       0.0       0.0  \n",
      "16       0.0       0.0  \n",
      "17       0.0       0.0  \n",
      "18       0.0       0.0  \n",
      "19       0.0       0.0  \n",
      "\n",
      "[20 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hills\\AppData\\Local\\Temp\\ipykernel_64848\\1095268161.py:61: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: None if x == '' else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading transArchive_201101_201103 to BigQuery...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CSV file: transArchive_201104.csv\n",
      "Detected delimiter: ,\n",
      "table 'leafy-sunrise-403222.wedge_data.transArchive_201104' not found, skipping deletion.\n",
      "Table 'leafy-sunrise-403222.wedge_data.transArchive_201104' not found, skipping deletion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hills\\AppData\\Local\\Temp\\ipykernel_64848\\1095268161.py:44: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 rows after cleaning:\n",
      "   datetime  register_no  emp_no  trans_no            upc  \\\n",
      "0       NaT            5      46         1  0007234001184   \n",
      "1       NaT            5      46         1  0000000000083   \n",
      "2       NaT            5      46         1  0000000000083   \n",
      "3       NaT            5      46         1              0   \n",
      "4       NaT            5      46         1              0   \n",
      "5       NaT            5      46         1       DISCOUNT   \n",
      "6       NaT            5      46         1            TAX   \n",
      "7       NaT            4      68         2  0020099000000   \n",
      "8       NaT            4      68         2              0   \n",
      "9       NaT            4      68         2              0   \n",
      "10      NaT            4      68         2       DISCOUNT   \n",
      "11      NaT            4      68         2            TAX   \n",
      "12      NaT           16      54         4  0000000040400   \n",
      "13      NaT           16      54         4  0020147200000   \n",
      "14      NaT           16      54         4              0   \n",
      "15      NaT           16      54         4              0   \n",
      "16      NaT           16      54         4       DISCOUNT   \n",
      "17      NaT           16      54         4            TAX   \n",
      "18      NaT            7       3         1  0076566710050   \n",
      "19      NaT            7       3         1  0076566710050   \n",
      "\n",
      "                           description trans_type trans_subtype trans_status  \\\n",
      "0     inchWhole Milk SR gallon Schinch          I     inch inch    inch inch   \n",
      "1     inchEggs O.Harmony Bulk Eachinch          I     inch inch    inch inch   \n",
      "2     inchEggs O.Harmony Bulk Eachinch          I     inch inch    inch inch   \n",
      "3                  inchCredit Cardinch          T            CC    inch inch   \n",
      "4                               Change          T            CA    inch inch   \n",
      "5                             Discount          I     inch inch    inch inch   \n",
      "6                                  Tax          A     inch inch    inch inch   \n",
      "7         inchFresh Flower Bouquetinch          I     inch inch    inch inch   \n",
      "8                  inchCredit Cardinch          T            CC    inch inch   \n",
      "9                               Change          T            CA    inch inch   \n",
      "10                            Discount          I     inch inch    inch inch   \n",
      "11                                 Tax          A     inch inch    inch inch   \n",
      "12     inchCoffee Hot Organic 12ozinch          I     inch inch    inch inch   \n",
      "13                    inchPad Thaiinch          I     inch inch    inch inch   \n",
      "14                                Cash          T            CA    inch inch   \n",
      "15                              Change          T            CA    inch inch   \n",
      "16                            Discount          I     inch inch    inch inch   \n",
      "17                                 Tax          A     inch inch    inch inch   \n",
      "18  inchTom Yum Soup Bowl 6oz Chuninch          I     inch inch    inch inch   \n",
      "19  inchTom Yum Soup Bowl 6oz Chuninch          I     inch inch    inch inch   \n",
      "\n",
      "    department  ...  batchHeaderID  local  organic  display  receipt  card_no  \\\n",
      "0            4  ...           True    0.0      0.0     True      0.0        3   \n",
      "1            4  ...           True    0.0      1.0     True      0.0        3   \n",
      "2            4  ...           True    0.0      1.0     True      0.0        3   \n",
      "3            0  ...           True    0.0      0.0     True      0.0        3   \n",
      "4            0  ...           True    0.0      0.0     True      0.0        3   \n",
      "5            0  ...           True    0.0      0.0     True      0.0        3   \n",
      "6            0  ...           True    0.0      0.0     True      0.0        3   \n",
      "7           18  ...           True    0.0      0.0     True      0.0    15125   \n",
      "8            0  ...           True    0.0      0.0     True      0.0    15125   \n",
      "9            0  ...           True    0.0      0.0     True      0.0    15125   \n",
      "10           0  ...           True    0.0      0.0     True      0.0    15125   \n",
      "11           0  ...           True    0.0      0.0     True      0.0    15125   \n",
      "12          14  ...           True    0.0      1.0     True      0.0        3   \n",
      "13           8  ...           True    0.0      0.0     True      0.0        3   \n",
      "14           0  ...           True    0.0      0.0     True      0.0        3   \n",
      "15           0  ...           True    0.0      0.0     True      0.0        3   \n",
      "16           0  ...           True    0.0      0.0     True      0.0        3   \n",
      "17           0  ...           True    0.0      0.0     True      0.0        3   \n",
      "18           1  ...           True    0.0      0.0     True      0.0    15047   \n",
      "19           1  ...           True    0.0      0.0     True      0.0    15047   \n",
      "\n",
      "    store  branch  match_id  trans_id  \n",
      "0       1       0       0.0         1  \n",
      "1       1       0       0.0         2  \n",
      "2       1       0       0.0         3  \n",
      "3       1       0       0.0        10  \n",
      "4       1       0       0.0        11  \n",
      "5       1       0       0.0        12  \n",
      "6       1       0       0.0        13  \n",
      "7       1       0       0.0         1  \n",
      "8       1       0       0.0         5  \n",
      "9       1       0       0.0         6  \n",
      "10      1       0       0.0         7  \n",
      "11      1       0       0.0         8  \n",
      "12      1       0       0.0         1  \n",
      "13      1       0       0.0         2  \n",
      "14      1       0       0.0         6  \n",
      "15      1       0       0.0         7  \n",
      "16      1       0       0.0         8  \n",
      "17      1       0       0.0         9  \n",
      "18      1       0       0.0         1  \n",
      "19      1       0       0.0         3  \n",
      "\n",
      "[20 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hills\\AppData\\Local\\Temp\\ipykernel_64848\\1095268161.py:61: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: None if x == '' else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading transArchive_201104 to BigQuery...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CSV file: transArchive_201105.csv\n",
      "Detected delimiter: ,\n",
      "table 'leafy-sunrise-403222.wedge_data.transArchive_201105' not found, skipping deletion.\n",
      "Table 'leafy-sunrise-403222.wedge_data.transArchive_201105' not found, skipping deletion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hills\\AppData\\Local\\Temp\\ipykernel_64848\\1095268161.py:44: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 rows after cleaning:\n",
      "   datetime  register_no  emp_no  trans_no            upc  \\\n",
      "0       NaT            5      36         2  0071833422113   \n",
      "1       NaT            5      36         2  0071833422113   \n",
      "2       NaT            5      36         2  0003997800957   \n",
      "3       NaT            5      36         2              0   \n",
      "4       NaT            5      36         2              0   \n",
      "5       NaT            5      36         2       DISCOUNT   \n",
      "6       NaT            5      36         2            TAX   \n",
      "7       NaT            4      20         2  0000000000101   \n",
      "8       NaT            4      20         2  0000000000138   \n",
      "9       NaT            4      20         2  0000000000051   \n",
      "10      NaT            4      20         2  0071575610020   \n",
      "11      NaT            4      20         2  0071575620011   \n",
      "12      NaT            4      20         2              0   \n",
      "13      NaT            4      20         2              0   \n",
      "14      NaT            4      20         2       DISCOUNT   \n",
      "15      NaT            4      20         2            TAX   \n",
      "16      NaT            7      47         1  0004227200269   \n",
      "17      NaT            7      47         1  0004227200132   \n",
      "18      NaT            7      47         1  0004227200130   \n",
      "19      NaT            7      47         1  0004227200313   \n",
      "\n",
      "                               description trans_type trans_subtype  \\\n",
      "0       inchTea Tree Mouthwash 16oz DEinch          I     inch inch   \n",
      "1       inchTea Tree Mouthwash 16oz DEinch          I     inch inch   \n",
      "2         inchO.Steelcut Oats 24oz BRMinch          I     inch inch   \n",
      "3                                     Cash          T            CA   \n",
      "4                                   Change          T            CA   \n",
      "5                                 Discount          I     inch inch   \n",
      "6                                      Tax          A     inch inch   \n",
      "7          inchAPPLES Braeburn Organicinch          I     inch inch   \n",
      "8           inchKiwi/Gold Kiwi Organicinch          I     inch inch   \n",
      "9                   inchBANANA Organicinch          I     inch inch   \n",
      "10            inchBlackberries 6oz pkginch          I     inch inch   \n",
      "11        inchO.Strawberries 16oz pkg.inch          I     inch inch   \n",
      "12                     inchCredit Cardinch          T            CC   \n",
      "13                                  Change          T            CA   \n",
      "14                                Discount          I     inch inch   \n",
      "15                                     Tax          A     inch inch   \n",
      "16  inchBlk.Bn.Tamale Verde 10.3oz Amyinch          I     inch inch   \n",
      "17         inchThai Stir-Fry 9.5oz Amyinch          I     inch inch   \n",
      "18  inchO.Asian Noodle StirFry 10oz Aminch          I     inch inch   \n",
      "19    inchO.Steelcut Oats Bowl 9oz Amyinch          I     inch inch   \n",
      "\n",
      "   trans_status  department  ...  batchHeaderID  local  organic  display  \\\n",
      "0     inch inch          11  ...           True    0.0      0.0     True   \n",
      "1     inch inch          11  ...           True    0.0      0.0     True   \n",
      "2     inch inch           1  ...           True    0.0      1.0     True   \n",
      "3     inch inch           0  ...           True    0.0      0.0     True   \n",
      "4     inch inch           0  ...           True    0.0      0.0     True   \n",
      "5     inch inch           0  ...           True    0.0      0.0     True   \n",
      "6     inch inch           0  ...           True    0.0      0.0     True   \n",
      "7     inch inch           2  ...           True    0.0      1.0     True   \n",
      "8     inch inch           2  ...           True    0.0      1.0     True   \n",
      "9     inch inch           2  ...           True    0.0      1.0     True   \n",
      "10    inch inch           2  ...           True    0.0      0.0     True   \n",
      "11    inch inch           2  ...           True    0.0      1.0     True   \n",
      "12    inch inch           0  ...           True    0.0      0.0     True   \n",
      "13    inch inch           0  ...           True    0.0      0.0     True   \n",
      "14    inch inch           0  ...           True    0.0      0.0     True   \n",
      "15    inch inch           0  ...           True    0.0      0.0     True   \n",
      "16    inch inch           6  ...           True    0.0      3.0     True   \n",
      "17    inch inch           6  ...           True    0.0      3.0     True   \n",
      "18    inch inch           6  ...           True    0.0      3.0     True   \n",
      "19    inch inch           6  ...           True    0.0      1.0     True   \n",
      "\n",
      "    receipt  card_no  store  branch  match_id  trans_id  \n",
      "0       0.0        3      1       0       0.0         1  \n",
      "1       0.0        3      1       0       0.0         2  \n",
      "2       0.0        3      1       0       0.0         3  \n",
      "3       0.0        3      1       0       0.0         7  \n",
      "4       0.0        3      1       0       0.0         8  \n",
      "5       0.0        3      1       0       0.0         9  \n",
      "6       0.0        3      1       0       0.0        10  \n",
      "7       0.0    15030      1       0       0.0         2  \n",
      "8       0.0    15030      1       0       0.0         3  \n",
      "9       0.0    15030      1       0       0.0         4  \n",
      "10      0.0    15030      1       0       0.0         5  \n",
      "11      0.0    15030      1       0       0.0         6  \n",
      "12      0.0    15030      1       0       0.0        17  \n",
      "13      0.0    15030      1       0       0.0        18  \n",
      "14      0.0    15030      1       0       0.0        19  \n",
      "15      0.0    15030      1       0       0.0        20  \n",
      "16      0.0    12539      1       0       0.0         4  \n",
      "17      0.0    12539      1       0       0.0         6  \n",
      "18      0.0    12539      1       0       0.0         8  \n",
      "19      0.0    12539      1       0       0.0        10  \n",
      "\n",
      "[20 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hills\\AppData\\Local\\Temp\\ipykernel_64848\\1095268161.py:61: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: None if x == '' else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading transArchive_201105 to BigQuery...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CSV file: transArchive_201106.csv\n",
      "Detected delimiter: ,\n",
      "table 'leafy-sunrise-403222.wedge_data.transArchive_201106' not found, skipping deletion.\n",
      "Table 'leafy-sunrise-403222.wedge_data.transArchive_201106' not found, skipping deletion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hills\\AppData\\Local\\Temp\\ipykernel_64848\\1095268161.py:44: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 rows after cleaning:\n",
      "   datetime  register_no  emp_no  trans_no            upc  \\\n",
      "0       NaT            4      32         1  0020123100000   \n",
      "1       NaT            4      32         1  0007514000500   \n",
      "2       NaT            4      32         1              0   \n",
      "3       NaT            4      32         1              0   \n",
      "4       NaT            4      32         1       DISCOUNT   \n",
      "5       NaT            4      32         1            TAX   \n",
      "6       NaT           16      54        10  0000000040210   \n",
      "7       NaT           16      54        10              0   \n",
      "8       NaT           16      54        10              0   \n",
      "9       NaT           16      54        10       DISCOUNT   \n",
      "10      NaT           16      54        10            TAX   \n",
      "11      NaT           16      54        12  0000000040421   \n",
      "12      NaT            5      31         2  0005260306595   \n",
      "13      NaT            5      31         2  0000000015625   \n",
      "14      NaT           16      54        12              0   \n",
      "15      NaT           16      54        12              0   \n",
      "16      NaT           16      54        12       DISCOUNT   \n",
      "17      NaT           16      54        12            TAX   \n",
      "18      NaT            5      31         2  0000000018446   \n",
      "19      NaT            5      31         2  0000000000017   \n",
      "\n",
      "                               description trans_type trans_subtype  \\\n",
      "0          inchTuna & Peas Pasta Saladinch          I     inch inch   \n",
      "1            inchSpring Water 1.5L CGeinch          I     inch inch   \n",
      "2                                     Cash          T            CA   \n",
      "3                                   Change          T            CA   \n",
      "4                                 Discount          I     inch inch   \n",
      "5                                      Tax          A     inch inch   \n",
      "6             inchPeachy Keen Smoothieinch          I     inch inch   \n",
      "7                      inchCredit Cardinch          T            CC   \n",
      "8                                   Change          T            CA   \n",
      "9                                 Discount          I     inch inch   \n",
      "10                                     Tax          A     inch inch   \n",
      "11         inchCoffee Hot Organic 16ozinch          I     inch inch   \n",
      "12          inchHazelnut Milk 32oz Pacinch          I     inch inch   \n",
      "13  inchSWEETENER Honey Raw/GardenFarminch          I     inch inch   \n",
      "14                                    Cash          T            CA   \n",
      "15                                  Change          T            CA   \n",
      "16                                Discount          I     inch inch   \n",
      "17                                     Tax          A     inch inch   \n",
      "18      inchRICE White Jasmine Organicinch          I     inch inch   \n",
      "19         inchLettuce Romaine Organicinch          I     inch inch   \n",
      "\n",
      "   trans_status  department  ...  batchHeaderID  local  organic  display  \\\n",
      "0     inch inch           8  ...           True    0.0      0.0     True   \n",
      "1     inch inch           1  ...           True    0.0      0.0     True   \n",
      "2     inch inch           0  ...           True    0.0      0.0     True   \n",
      "3     inch inch           0  ...           True    0.0      0.0     True   \n",
      "4     inch inch           0  ...           True    0.0      0.0     True   \n",
      "5     inch inch           0  ...           True    0.0      0.0     True   \n",
      "6     inch inch          14  ...           True    0.0      0.0     True   \n",
      "7     inch inch           0  ...           True    0.0      0.0     True   \n",
      "8     inch inch           0  ...           True    0.0      0.0     True   \n",
      "9     inch inch           0  ...           True    0.0      0.0     True   \n",
      "10    inch inch           0  ...           True    0.0      0.0     True   \n",
      "11    inch inch          14  ...           True    0.0      1.0     True   \n",
      "12    inch inch           1  ...           True    0.0      0.0     True   \n",
      "13    inch inch           3  ...           True    0.0      0.0     True   \n",
      "14    inch inch           0  ...           True    0.0      0.0     True   \n",
      "15    inch inch           0  ...           True    0.0      0.0     True   \n",
      "16    inch inch           0  ...           True    0.0      0.0     True   \n",
      "17    inch inch           0  ...           True    0.0      0.0     True   \n",
      "18    inch inch           3  ...           True    0.0      1.0     True   \n",
      "19    inch inch           2  ...           True    0.0      1.0     True   \n",
      "\n",
      "    receipt  card_no  store  branch  match_id  trans_id  \n",
      "0       0.0        3      1       0       0.0         1  \n",
      "1       0.0        3      1       0       0.0         2  \n",
      "2       0.0        3      1       0       0.0         6  \n",
      "3       0.0        3      1       0       0.0         7  \n",
      "4       0.0        3      1       0       0.0         8  \n",
      "5       0.0        3      1       0       0.0         9  \n",
      "6       0.0    12539      1       0       0.0         1  \n",
      "7       0.0    12539      1       0       0.0         5  \n",
      "8       0.0    12539      1       0       0.0         6  \n",
      "9       0.0    12539      1       0       0.0         7  \n",
      "10      0.0    12539      1       0       0.0         8  \n",
      "11      0.0        3      1       0       0.0         1  \n",
      "12      0.0    23170      1       0       0.0         1  \n",
      "13      0.0    23170      1       0       0.0         4  \n",
      "14      0.0        3      1       0       0.0         5  \n",
      "15      0.0        3      1       0       0.0         6  \n",
      "16      0.0        3      1       0       0.0         7  \n",
      "17      0.0        3      1       0       0.0         8  \n",
      "18      0.0    23170      1       0       0.0         6  \n",
      "19      0.0    23170      1       0       0.0         7  \n",
      "\n",
      "[20 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hills\\AppData\\Local\\Temp\\ipykernel_64848\\1095268161.py:61: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: None if x == '' else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading transArchive_201106 to BigQuery...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CSV file: transArchive_201107_201109.csv\n",
      "Detected delimiter: ,\n",
      "table 'leafy-sunrise-403222.wedge_data.transArchive_201107_201109' not found, skipping deletion.\n",
      "Table 'leafy-sunrise-403222.wedge_data.transArchive_201107_201109' not found, skipping deletion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hills\\AppData\\Local\\Temp\\ipykernel_64848\\1095268161.py:44: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 rows after cleaning:\n",
      "   datetime  register_no  emp_no  trans_no                    upc  \\\n",
      "0       NaT          0.0     0.0       0.0            inchupcinch   \n",
      "1       NaT          0.0     0.0       0.0        inch1.19DP9inch   \n",
      "2       NaT          0.0     0.0       0.0  inch0000000015627inch   \n",
      "3       NaT          0.0     0.0       0.0  inch0000000000042inch   \n",
      "4       NaT          0.0     0.0       0.0  inch0000000000042inch   \n",
      "5       NaT          0.0     0.0       0.0  inch0001707720116inch   \n",
      "6       NaT          0.0     0.0       0.0  inch0020694600000inch   \n",
      "7       NaT          0.0     0.0       0.0  inch0000000008058inch   \n",
      "8       NaT          0.0     0.0       0.0              inch0inch   \n",
      "9       NaT          0.0     0.0       0.0              inch0inch   \n",
      "10      NaT          0.0     0.0       0.0       inchDISCOUNTinch   \n",
      "11      NaT          0.0     0.0       0.0            inchTAXinch   \n",
      "12      NaT          0.0     0.0       0.0              inch0inch   \n",
      "13      NaT          0.0     0.0       0.0              inch0inch   \n",
      "14      NaT          0.0     0.0       0.0       inchDISCOUNTinch   \n",
      "15      NaT          0.0     0.0       0.0            inchTAXinch   \n",
      "16      NaT          0.0     0.0       0.0  inch0007572000061inch   \n",
      "17      NaT          0.0     0.0       0.0              inch0inch   \n",
      "18      NaT          0.0     0.0       0.0              inch0inch   \n",
      "19      NaT          0.0     0.0       0.0       inchDISCOUNTinch   \n",
      "\n",
      "                              description          trans_type  \\\n",
      "0                     inchdescriptioninch  inchtrans_typeinch   \n",
      "1                       inchGEN MERCHinch           inchDinch   \n",
      "2   inchSWEETENER Honey Raw/Ames Farminch           inchIinch   \n",
      "3                inchMultigrain Breadinch           inchIinch   \n",
      "4                inchMultigrain Breadinch           inchIinch   \n",
      "5      inchLifeway Farmer Cheese 16ozinch           inchIinch   \n",
      "6          inchHerring In Cream Sauceinch           inchIinch   \n",
      "7          inchBUS PASS SV Go-To Cardinch           inchIinch   \n",
      "8                     inchCredit Cardinch           inchTinch   \n",
      "9                          inchChangeinch           inchTinch   \n",
      "10                       inchDiscountinch           inchIinch   \n",
      "11                            inchTaxinch           inchAinch   \n",
      "12                    inchCredit Cardinch           inchTinch   \n",
      "13                         inchChangeinch           inchTinch   \n",
      "14                       inchDiscountinch           inchIinch   \n",
      "15                            inchTaxinch           inchAinch   \n",
      "16         inchNat.Spring Water 1L PSinch           inchIinch   \n",
      "17                           inchCashinch           inchTinch   \n",
      "18                         inchChangeinch           inchTinch   \n",
      "19                       inchDiscountinch           inchIinch   \n",
      "\n",
      "            trans_subtype          trans_status  department  ...  \\\n",
      "0   inchtrans_subtypeinch  inchtrans_statusinch         0.0  ...   \n",
      "1               inch inch             inch inch         0.0  ...   \n",
      "2               inch inch             inch inch         0.0  ...   \n",
      "3               inch inch             inch inch         0.0  ...   \n",
      "4               inch inch             inch inch         0.0  ...   \n",
      "5               inch inch             inch inch         0.0  ...   \n",
      "6               inch inch             inch inch         0.0  ...   \n",
      "7               inch inch             inch inch         0.0  ...   \n",
      "8              inchCCinch             inch inch         0.0  ...   \n",
      "9              inchCAinch             inch inch         0.0  ...   \n",
      "10              inch inch             inch inch         0.0  ...   \n",
      "11              inch inch             inch inch         0.0  ...   \n",
      "12             inchCCinch             inch inch         0.0  ...   \n",
      "13             inchCAinch             inch inch         0.0  ...   \n",
      "14              inch inch             inch inch         0.0  ...   \n",
      "15              inch inch             inch inch         0.0  ...   \n",
      "16              inch inch             inch inch         0.0  ...   \n",
      "17             inchCAinch             inch inch         0.0  ...   \n",
      "18             inchCAinch             inch inch         0.0  ...   \n",
      "19              inch inch             inch inch         0.0  ...   \n",
      "\n",
      "    batchHeaderID  local  organic  display  receipt  card_no  store  branch  \\\n",
      "0            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "1            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "2            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "3            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "4            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "5            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "6            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "7            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "8            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "9            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "10           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "11           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "12           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "13           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "14           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "15           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "16           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "17           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "18           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "19           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "\n",
      "    match_id  trans_id  \n",
      "0        0.0       0.0  \n",
      "1        0.0       0.0  \n",
      "2        0.0       0.0  \n",
      "3        0.0       0.0  \n",
      "4        0.0       0.0  \n",
      "5        0.0       0.0  \n",
      "6        0.0       0.0  \n",
      "7        0.0       0.0  \n",
      "8        0.0       0.0  \n",
      "9        0.0       0.0  \n",
      "10       0.0       0.0  \n",
      "11       0.0       0.0  \n",
      "12       0.0       0.0  \n",
      "13       0.0       0.0  \n",
      "14       0.0       0.0  \n",
      "15       0.0       0.0  \n",
      "16       0.0       0.0  \n",
      "17       0.0       0.0  \n",
      "18       0.0       0.0  \n",
      "19       0.0       0.0  \n",
      "\n",
      "[20 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hills\\AppData\\Local\\Temp\\ipykernel_64848\\1095268161.py:61: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: None if x == '' else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading transArchive_201107_201109 to BigQuery...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CSV file: transArchive_201110_201112.csv\n",
      "Detected delimiter: ,\n",
      "table 'leafy-sunrise-403222.wedge_data.transArchive_201110_201112' not found, skipping deletion.\n",
      "Table 'leafy-sunrise-403222.wedge_data.transArchive_201110_201112' not found, skipping deletion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hills\\AppData\\Local\\Temp\\ipykernel_64848\\1095268161.py:44: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 rows after cleaning:\n",
      "   datetime  register_no  emp_no  trans_no                    upc  \\\n",
      "0       NaT          0.0     0.0       0.0            inchupcinch   \n",
      "1       NaT          0.0     0.0       0.0  inch0000000040423inch   \n",
      "2       NaT          0.0     0.0       0.0              inch0inch   \n",
      "3       NaT          0.0     0.0       0.0              inch0inch   \n",
      "4       NaT          0.0     0.0       0.0       inchDISCOUNTinch   \n",
      "5       NaT          0.0     0.0       0.0            inchTAXinch   \n",
      "6       NaT          0.0     0.0       0.0  inch0000000040401inch   \n",
      "7       NaT          0.0     0.0       0.0  inch0000000003602inch   \n",
      "8       NaT          0.0     0.0       0.0  inch0000000000049inch   \n",
      "9       NaT          0.0     0.0       0.0  inch0000000003602inch   \n",
      "10      NaT          0.0     0.0       0.0              inch0inch   \n",
      "11      NaT          0.0     0.0       0.0              inch0inch   \n",
      "12      NaT          0.0     0.0       0.0       inchDISCOUNTinch   \n",
      "13      NaT          0.0     0.0       0.0            inchTAXinch   \n",
      "14      NaT          0.0     0.0       0.0  inch0000000000039inch   \n",
      "15      NaT          0.0     0.0       0.0              inch0inch   \n",
      "16      NaT          0.0     0.0       0.0              inch0inch   \n",
      "17      NaT          0.0     0.0       0.0       inchDISCOUNTinch   \n",
      "18      NaT          0.0     0.0       0.0            inchTAXinch   \n",
      "19      NaT          0.0     0.0       0.0  inch0006098821203inch   \n",
      "\n",
      "                           description          trans_type  \\\n",
      "0                  inchdescriptioninch  inchtrans_typeinch   \n",
      "1                 inchCC Chai 12ozinch           inchIinch   \n",
      "2                         inchCashinch           inchTinch   \n",
      "3                       inchChangeinch           inchTinch   \n",
      "4                     inchDiscountinch           inchIinch   \n",
      "5                          inchTaxinch           inchAinch   \n",
      "6      inchCoffee Hot Organic 20ozinch           inchIinch   \n",
      "7   inchDun Laoghaire Bar Soap 6ozinch           inchIinch   \n",
      "8                 inchWedge Muffininch           inchIinch   \n",
      "9   inchDun Laoghaire Bar Soap 6ozinch           inchIinch   \n",
      "10                        inchCashinch           inchTinch   \n",
      "11                      inchChangeinch           inchTinch   \n",
      "12                    inchDiscountinch           inchIinch   \n",
      "13                         inchTaxinch           inchAinch   \n",
      "14                 inchWedge Sconeinch           inchIinch   \n",
      "15                        inchCashinch           inchTinch   \n",
      "16                      inchChangeinch           inchTinch   \n",
      "17                    inchDiscountinch           inchIinch   \n",
      "18                         inchTaxinch           inchAinch   \n",
      "19    inchYogurt Starter Yogourmetinch           inchIinch   \n",
      "\n",
      "            trans_subtype          trans_status  department  ...  \\\n",
      "0   inchtrans_subtypeinch  inchtrans_statusinch         0.0  ...   \n",
      "1               inch inch             inch inch         0.0  ...   \n",
      "2              inchCAinch             inch inch         0.0  ...   \n",
      "3              inchCAinch             inch inch         0.0  ...   \n",
      "4               inch inch             inch inch         0.0  ...   \n",
      "5               inch inch             inch inch         0.0  ...   \n",
      "6               inch inch             inch inch         0.0  ...   \n",
      "7               inch inch             inch inch         0.0  ...   \n",
      "8               inch inch             inch inch         0.0  ...   \n",
      "9               inch inch             inch inch         0.0  ...   \n",
      "10             inchCAinch             inch inch         0.0  ...   \n",
      "11             inchCAinch             inch inch         0.0  ...   \n",
      "12              inch inch             inch inch         0.0  ...   \n",
      "13              inch inch             inch inch         0.0  ...   \n",
      "14              inch inch             inch inch         0.0  ...   \n",
      "15             inchCAinch             inch inch         0.0  ...   \n",
      "16             inchCAinch             inch inch         0.0  ...   \n",
      "17              inch inch             inch inch         0.0  ...   \n",
      "18              inch inch             inch inch         0.0  ...   \n",
      "19              inch inch             inch inch         0.0  ...   \n",
      "\n",
      "    batchHeaderID  local  organic  display  receipt  card_no  store  branch  \\\n",
      "0            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "1            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "2            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "3            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "4            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "5            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "6            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "7            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "8            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "9            True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "10           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "11           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "12           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "13           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "14           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "15           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "16           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "17           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "18           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "19           True    0.0      0.0     True      0.0      0.0    0.0     0.0   \n",
      "\n",
      "    match_id  trans_id  \n",
      "0        0.0       0.0  \n",
      "1        0.0       0.0  \n",
      "2        0.0       0.0  \n",
      "3        0.0       0.0  \n",
      "4        0.0       0.0  \n",
      "5        0.0       0.0  \n",
      "6        0.0       0.0  \n",
      "7        0.0       0.0  \n",
      "8        0.0       0.0  \n",
      "9        0.0       0.0  \n",
      "10       0.0       0.0  \n",
      "11       0.0       0.0  \n",
      "12       0.0       0.0  \n",
      "13       0.0       0.0  \n",
      "14       0.0       0.0  \n",
      "15       0.0       0.0  \n",
      "16       0.0       0.0  \n",
      "17       0.0       0.0  \n",
      "18       0.0       0.0  \n",
      "19       0.0       0.0  \n",
      "\n",
      "[20 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hills\\AppData\\Local\\Temp\\ipykernel_64848\\1095268161.py:61: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: None if x == '' else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading transArchive_201110_201112 to BigQuery...\n"
     ]
    }
   ],
   "source": [
    "# move through all files in the directory\n",
    "for root, dirs, files in os.walk(output_folder):\n",
    "    for file in files:\n",
    "        full_path = os.path.join(root, file)\n",
    "\n",
    "        if file.endswith('.csv'):\n",
    "            print(f\"Found CSV file: {file}\")\n",
    "\n",
    "            delimiter = detect_delimiter(full_path)\n",
    "            print(f\"Detected delimiter: {delimiter}\")\n",
    "\n",
    "            # Reading CSV with correct handling of quoted fields\n",
    "            df = pd.read_csv(full_path, delimiter=delimiter, quotechar='\"', dtype=str, low_memory=False)\n",
    "\n",
    "            table_name = file.replace('.csv', '')\n",
    "\n",
    "            # Drop the table if it exists\n",
    "            drop_table_if_exists(gbq_dataset_id, table_name, credentials, gbq_proj_id)\n",
    "            client = bigquery.Client(credentials=credentials, project=gbq_proj_id)\n",
    "\n",
    "            # Construct the fully-qualified table_id without \".csv\" extension\n",
    "            table_id = f\"{gbq_proj_id}.{gbq_dataset_id}.{table_name}\"\n",
    "\n",
    "            try:\n",
    "                client.delete_table(table_id)\n",
    "                print(f\"Deleted table '{table_id}'\")\n",
    "            except NotFound:\n",
    "                print(f\"Table '{table_id}' not found, skipping deletion.\")\n",
    "\n",
    "            # Clean the DataFrame\n",
    "            df = clean_dataframe(df)\n",
    "\n",
    "            # Modify the field names to comply with the gbq rules\n",
    "            df.columns = [col.lower().replace(';', '') for col in df.columns]\n",
    "\n",
    "            print(f\"Uploading {table_name} to BigQuery...\")\n",
    "            pandas_gbq.to_gbq(df, f\"{gbq_dataset_id}.{table_name}\", project_id=gbq_proj_id, if_exists='replace', credentials=credentials, table_schema=schema)\n",
    "            del df  # Clean the DataFrame from memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hi John - cells below are for reference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing code chunk\n",
    "\n",
    "chunk_size = 50000\n",
    "\n",
    "def drop_table_if_exists(gbq_dataset_id, table_name, credentials, gbq_proj_id):\n",
    "    client = bigquery.Client(credentials=credentials, project=gbq_proj_id)\n",
    "    table_id = f\"{gbq_proj_id}.{gbq_dataset_id}.{table_name}\"\n",
    "\n",
    "    try:\n",
    "        client.delete_table(table_id)\n",
    "        print(f\"deleted table '{table_id}'\")\n",
    "    except NotFound:\n",
    "        print(f\"table '{table_id}' not found, skipping deletion.\")\n",
    "\n",
    "def detect_delimiter(filename):\n",
    "    with open(filename,'r') as file:\n",
    "        first_line = file.readline()\n",
    "        return \";\" if \";\" in first_line else \",\"\n",
    "    \n",
    "def clean_dataframe(df):\n",
    "    float_columns = [\n",
    "        'register_no', 'emp_no', 'trans_no', 'department', 'quantity', 'Scale', 'cost', 'unitPrice', 'total', 'regPrice'\n",
    "        , 'altPrice', 'tax', 'taxexempt', 'foodstamp', 'wicable', 'discount', 'memDiscount', 'discountable', 'discounttype'\n",
    "        , 'voided', 'percentDiscount', 'ItemQtty', 'volDiscType', 'volume', 'VolSpecial', 'mixMatch', 'matched', 'numflag'\n",
    "        , 'itemstatus', 'tenderstatus', 'varflag', 'local', 'organic', 'receipt', 'card_no', 'store', 'branch', 'match_id'\n",
    "        ,'trans_id'\n",
    "    ]\n",
    "\n",
    "    boolean_columns = [ 'memType', 'staff', 'batchHeaderID', 'display']\n",
    "\n",
    "    string_columns = ['upc', 'description', 'trans_type', 'trans_subtype', 'trans_status', 'charflag']\n",
    "\n",
    "    for col in string_columns:\n",
    "        if col in df.columns:\n",
    "            df[col]  = df[col].astype(str)\n",
    "            df[col] = df[col].str.replace('\"', '', regex=False)\n",
    "\n",
    "    for col in float_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    df[float_columns] = df[float_columns].fillna(0)\n",
    "\n",
    "    for col in boolean_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(bool)\n",
    "\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
    "\n",
    "    replace_strings = [\"\\\\n\", \"\\\\\\\\\", \"nan\", \"NULL\"]\n",
    "    df.replace(replace_strings, \"\", inplace=True)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].str.strip()\n",
    "\n",
    "    for col in ['itemQtty', 'reciept']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).str.replace('\"', '', regex=False)\n",
    "\n",
    "    # Print the first 20 rows for inspection\n",
    "    print(\"First 20 rows after cleaning:\")\n",
    "    print(df.head(20))\n",
    "\n",
    "    df = df.applymap(lambda x: None if x == '' else x)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hold on to this while I test another chunk - more than likley delete\n",
    "\n",
    "chunk_size = 50000\n",
    "\n",
    "def drop_table_if_exists(gbq_dataset_id, table_name, credentials, gbq_proj_id):\n",
    "    client = bigquery.Client(credentials=credentials, project=gbq_proj_id)\n",
    "    table_id = f\"{gbq_proj_id}.{gbq_dataset_id}.{table_name}\"\n",
    "\n",
    "    try:\n",
    "        client.delete_table(table_id)\n",
    "        print(f\"deleted table '{table_id}'\")\n",
    "    except NotFound:\n",
    "        print(f\"table '{table_id}' not found, skipping deletion.\")\n",
    "\n",
    "def detect_delimiter(filename):\n",
    "    with open(filename,'r') as file:\n",
    "        first_line = file.readline()\n",
    "        return \";\" if \";\" in first_line else \",\"\n",
    "    \n",
    "def clean_dataframe(df):\n",
    "    float_columns = [\n",
    "        'register_no', 'emp_no', 'trans_no', 'department', 'quantity', 'Scale', 'cost', 'unitPrice', 'total', 'regPrice'\n",
    "        , 'altPrice', 'tax', 'taxexempt', 'foodstamp', 'wicable', 'discount', 'memDiscount', 'discountable', 'discounttype'\n",
    "        , 'voided', 'percentDiscount', 'itemQtty', 'volDiscType', 'volume', 'VolSpecial', 'mixMatch', 'matched', 'numflag'\n",
    "        , 'itemstatus', 'tenderstatus', 'varflag', 'local', 'organic', 'reciept', 'card_no', 'store', 'branch', 'match_id'\n",
    "        ,'trans_id'\n",
    "    ]\n",
    "\n",
    "    boolean_columns = [ 'memType', 'staff', 'batchHeaderID', 'display']\n",
    "\n",
    "    string_columns = ['upc', 'description', 'trans_type', 'trans_subtype', 'trans_status', 'charflag']\n",
    "\n",
    "        # Check if columns exist before applying operations\n",
    "\n",
    "    # List of columns to check and clean\n",
    "    #columns_to_clean = ['itemQtty', 'reciept']\n",
    "\n",
    "   # for col in columns_to_clean:\n",
    "    #    if col in df.columns:\n",
    "     #       if col == 'charflag':\n",
    "      #          df[col] = df[col].str.strip()\n",
    "       #     elif col in ['itemQtty', 'reciept']:\n",
    "        #        df[col] = df[col].astype(str).str.replace('\"', '', regex=False)\n",
    "\n",
    "\n",
    "    for col in string_columns:\n",
    "        if col in df.columns:\n",
    "            df[col]  = df[col].astype(str)\n",
    "            df [col] = df [col].str.replace('\"', '', regex=False)\n",
    "\n",
    "    for col in float_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    df[float_columns] = df[float_columns].fillna(0)\n",
    "\n",
    "    for col in boolean_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(bool)\n",
    "\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
    "    \n",
    "    replace_strings = [\"\\\\n\", \"\\\\\\\\\", \"nan\", \"NULL\"]\n",
    "    df.replace(replace_strings, \"\", inplace=True)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].str.strip()\n",
    "            #df[col] = df[col].str.replace('\\\\\\\"', '', regex=False)\n",
    "\n",
    "    for col in df.columns: # added these three lines trying to problem solve next chuck for gbq file path\n",
    "        if col == 'charflag' and col in df.columns:\n",
    "            df[col] = df[col].str.strip()\n",
    "\n",
    "    df = df.applymap(lambda x: None if x == '' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#duplicate code to play with\n",
    "\n",
    "# move through all files in the directory\n",
    "for root, dirs, files in os.walk(output_folder):\n",
    "    for file in files:\n",
    "        full_path = os.path.join(root, file)\n",
    "        \n",
    "        if file.endswith('.csv'):\n",
    "            print(f\"Found CSV file: {file}\")\n",
    "\n",
    "            delimiter = detect_delimiter(full_path)\n",
    "            print(f\"detected delimiter: {delimiter}\")\n",
    "\n",
    "            # reading csv with correct handling of quoted fields\n",
    "            chunk_iter = pd.read_csv(full_path, delimiter=delimiter, quotechar='\"', chunksize=chunk_size, dtype=str, low_memory=False)\n",
    "\n",
    "            table_name = file.replace('.csv', '')\n",
    "\n",
    "            # drop the table if it exists\n",
    "            drop_table_if_exists(gbq_dataset_id, table_name, credentials, gbq_proj_id)\n",
    "            client = bigquery.Client(credentials=credentials, project=gbq_proj_id)\n",
    "    \n",
    "            # Construct the fully-qualified table_id without \".csv\" extension\n",
    "            table_id = f\"{gbq_proj_id}.{gbq_dataset_id}.{table_name}\"\n",
    "\n",
    "            try:\n",
    "                client.delete_table(table_id)\n",
    "                print(f\"deleted table '{table_id}'\")\n",
    "            except NotFound:\n",
    "                print(f\"table '{table_id}' not found, skipping deletion.\")\n",
    "\n",
    "            print(f\"reading csv file in chunks: {file}...\")\n",
    "            for idx, chunk_df in enumerate(chunk_iter):\n",
    "                # clean the DF\n",
    "                chunk_df = clean_dataframe(chunk_df)\n",
    "\n",
    "                # modify the field names to comply with the gbq rules\n",
    "                chunk_df.columns = [col.lower().replace(';', '') for col in chunk_df.columns]\n",
    "\n",
    "                print(f\"uploading chunk {idx + 1} to {table_name}...\")\n",
    "                if idx == 0:\n",
    "                    # for the first chunk create the table with the defined schema\n",
    "                    pandas_gbq.to_gbq(chunk_df, f\"{gbq_dataset_id}.{table_name}\", project_id=gbq_proj_id, if_exists='replace', credentials=credentials, table_schema=schema)\n",
    "                else:\n",
    "                    # for subsequent chunks, append to the table \n",
    "                    pandas_gbq.to_gbq(chunk_df, f\"{gbq_dataset_id}.{table_name}\", project_id=gbq_proj_id, if_exists='append', credentials=credentials)\n",
    "                del chunk_df  # clean the chunk from memory\n",
    "        break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# move through all files in the directory\n",
    "for root, dirs, files in os.walk(output_folder):\n",
    "    for file in files:\n",
    "        full_path = os.path.join(root, file)\n",
    "        \n",
    "        if file.endswith('.csv'):\n",
    "            print(f\"Found CSV file: {file}\")\n",
    "\n",
    "            delimiter = detect_delimiter(full_path)\n",
    "            print(f\"detected delimiter: {delimiter}\")\n",
    "\n",
    "            #reading csv with correct handeling of quoted fields\n",
    "            chunk_iter = pd.read_csv(full_path, delimiter=delimiter,quotechar='\"', chunksize=chunk_size, dtype=str, low_memory=False)\n",
    "\n",
    "            table_name = file.replace('data.csv', '')\n",
    "\n",
    "            #drop the table if it exists\n",
    "            drop_table_if_exists(gbq_dataset_id, table_name, credentials, gbq_proj_id)\n",
    "            client = bigquery.Client(credentials=credentials, project=gbq_proj_id)\n",
    "    \n",
    "                # Construct the fully-qualified table_id\n",
    "            table_id = f\"{gbq_proj_id}.{gbq_dataset_id}.{table_name}\"\n",
    "\n",
    "            try:\n",
    "                client.delete_table(table_id)\n",
    "                print(f\"deleted table '{table_id}'\")\n",
    "            except NotFound:\n",
    "                print(f\"table '{table_id}' not found, skipping deletion.\")\n",
    "\n",
    "            print(f\"reading csv file in chucks: {file}...\")\n",
    "            for idx, chunk_df in enumerate(chunk_iter):\n",
    "                #clean the DF\n",
    "                chunk_df = clean_dataframe(chunk_df)\n",
    "\n",
    "                #modify the field names to comply with the gbq rules\n",
    "                chunk_df.columns = [col.lower().replace(';','') for col in chunk_df.columns]\n",
    "\n",
    "                print(f\"uploading chunk {idx + 1} to {table_name}...\")\n",
    "                if idx == 0:\n",
    "                    # for the first chuck create the table with the defined schema\n",
    "                    pandas_gbq.to_gbq(chunk_df, f\"{gbq_dataset_id}.{table_name}\", project_id=gbq_proj_id, if_exists='replace', credentials=credentials, table_schema=schema)\n",
    "                else:\n",
    "                    # for subsuquent chunks, append to the table \n",
    "                    pandas_gbq.to_gbq(chunk_df, f\"{gbq_dataset_id}.{table_name}\", project_id=gbq_proj_id, if_exists='append', credentials=credentials)\n",
    "                del chunk_df # clean the chunk from memory\n",
    "        break\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
